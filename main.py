# main.py ä¸»é€»è¾‘ï¼šåŒ…æ‹¬å­—æ®µæ‹¼æŽ¥ã€æ¨¡æ‹Ÿè¯·æ±‚
import os
import re
import json
import time
import random
import logging
import hashlib
import requests
import urllib.parse
from push import push
from config import data, headers, cookies, READ_NUM, PUSH_METHOD, book, chapter

# é…ç½®æ—¥å¿—æ ¼å¼
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)-8s - %(message)s')

# åŠ å¯†ç›åŠå…¶å®ƒé»˜è®¤å€¼
KEY = "3c5c8717f3daf09iop3423zafeqoi"
READ_URL = "https://weread.qq.com/web/book/read"
RENEW_URL = "https://weread.qq.com/web/login/renewal"
FIX_SYNCKEY_URL = "https://weread.qq.com/web/book/chapterInfos"


def _str_to_bool(value):
    """ç»Ÿä¸€å¤„ç†å¸ƒå°”é…ç½®å­—ç¬¦ä¸²"""
    if isinstance(value, bool):
        return value
    if value is None:
        return False
    return str(value).strip().lower() in {"1", "true", "t", "yes"}


def _build_cookie_payload():
    """æž„é€ ç»­ç­¾è¯·æ±‚ä½“ï¼Œå…¼å®¹ weread-bot çš„é…ç½®æ–¹å¼"""
    env_flag = os.getenv("HACK_COOKIE_REFRESH_QL")
    if env_flag is not None:
        ql_flag = _str_to_bool(env_flag)
    else:
        ql_flag = _str_to_bool(cookies.get("wr_ql"))

    payload = {"rq": "%2Fweb%2Fbook%2Fread", "ql": ql_flag}
    logging.debug("ðŸ”§ ç»­ç­¾ payload: %s", payload)
    return payload


def encode_data(data):
    """æ•°æ®ç¼–ç """
    return '&'.join(f"{k}={urllib.parse.quote(str(data[k]), safe='')}" for k in sorted(data.keys()))


def cal_hash(input_string):
    """è®¡ç®—å“ˆå¸Œå€¼"""
    _7032f5 = 0x15051505
    _cc1055 = _7032f5
    length = len(input_string)
    _19094e = length - 1

    while _19094e > 0:
        _7032f5 = 0x7fffffff & (_7032f5 ^ ord(input_string[_19094e]) << (length - _19094e) % 30)
        _cc1055 = 0x7fffffff & (_cc1055 ^ ord(input_string[_19094e - 1]) << _19094e % 30)
        _19094e -= 2

    return hex(_7032f5 + _cc1055)[2:].lower()

def _refresh_cookie_once():
    """è°ƒç”¨ç»­ç­¾æŽ¥å£åˆ·æ–° wr_skeyï¼ŒæˆåŠŸè¿”å›ž True"""
    logging.info("ðŸª åˆ·æ–°cookie...")
    payload = _build_cookie_payload()
    try:
        response = requests.post(
            RENEW_URL,
            headers=headers,
            cookies=cookies,
            json=payload,
            timeout=10,
        )
    except requests.RequestException as exc:
        logging.error("âŒ Cookieåˆ·æ–°å¤±è´¥ï¼Œè¯·æ±‚å¼‚å¸¸ï¼š%s", exc)
        return False

    new_skey = response.cookies.get("wr_skey")

    if not new_skey:
        set_cookie = response.headers.get("Set-Cookie", "")
        for cookie in set_cookie.split(','):
            if "wr_skey" in cookie:
                parts = cookie.split(';')[0]
                if '=' in parts:
                    new_skey = parts.split('=', 1)[1].strip()
                    break

    if not new_skey:
        logging.error(
            "âŒ Cookieåˆ·æ–°å¤±è´¥ï¼Œæœªæ‰¾åˆ° wr_skeyï¼Œstatus=%s, body=%s",
            response.status_code,
            response.text,
        )
        return False

    cookies['wr_skey'] = new_skey
    logging.info("âœ… Cookieåˆ·æ–°æˆåŠŸï¼Œæ–°å¯†é’¥: %s***", new_skey[:8])
    return True

def fix_no_synckey():
    requests.post(FIX_SYNCKEY_URL, headers=headers, cookies=cookies,
                             data=json.dumps({"bookIds":["3300060341"]}, separators=(',', ':')))

def refresh_cookie():
    if _refresh_cookie_once():
        logging.info("ðŸ”„ é‡æ–°æœ¬æ¬¡é˜…è¯»ã€‚")
        return

    ERROR_CODE = "âŒ æ— æ³•èŽ·å–æ–°å¯†é’¥æˆ–è€…WXREAD_CURL_BASHé…ç½®æœ‰è¯¯ï¼Œç»ˆæ­¢è¿è¡Œã€‚"
    logging.error(ERROR_CODE)
    try:
        push(ERROR_CODE, PUSH_METHOD)
    except Exception:
        logging.exception("âŒ æŽ¨é€é€šçŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ PUSH_METHOD åŠå…¶é…ç½®ã€‚")
        raise
    raise Exception(ERROR_CODE)

refresh_cookie()
index = 1
lastTime = int(time.time()) - 30
logging.info(f"â±ï¸ ä¸€å…±éœ€è¦é˜…è¯» {READ_NUM} æ¬¡...")

while index <= READ_NUM:
    data.pop('s')
    data['b'] = random.choice(book)
    data['c'] = random.choice(chapter)
    thisTime = int(time.time())
    data['ct'] = thisTime
    data['rt'] = thisTime - lastTime
    data['ts'] = int(thisTime * 1000) + random.randint(0, 1000)
    data['rn'] = random.randint(0, 1000)
    data['sg'] = hashlib.sha256(f"{data['ts']}{data['rn']}{KEY}".encode()).hexdigest()
    data['s'] = cal_hash(encode_data(data))

    logging.info(f"â±ï¸ å°è¯•ç¬¬ {index} æ¬¡é˜…è¯»...")
    logging.info(f"ðŸ“• data: {data}")
    response = requests.post(READ_URL, headers=headers, cookies=cookies, data=json.dumps(data, separators=(',', ':')))
    resData = response.json()
    logging.info(f"ðŸ“• response: {resData}")

    if 'succ' in resData:
        if 'synckey' in resData:
            lastTime = thisTime
            index += 1
            time.sleep(30)
            logging.info(f"âœ… é˜…è¯»æˆåŠŸï¼Œé˜…è¯»è¿›åº¦ï¼š{(index - 1) * 0.5} åˆ†é’Ÿ")
        else:
            logging.warning("âŒ æ— synckey, å°è¯•ä¿®å¤...")
            fix_no_synckey()
    else:
        logging.warning("âŒ cookie å·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
        refresh_cookie()

logging.info("ðŸŽ‰ é˜…è¯»è„šæœ¬å·²å®Œæˆï¼")

if PUSH_METHOD not in (None, ''):
    logging.info("â±ï¸ å¼€å§‹æŽ¨é€...")
    push(f"ðŸŽ‰ å¾®ä¿¡è¯»ä¹¦è‡ªåŠ¨é˜…è¯»å®Œæˆï¼\nâ±ï¸ é˜…è¯»æ—¶é•¿ï¼š{(index - 1) * 0.5}åˆ†é’Ÿã€‚", PUSH_METHOD)
